server:
  port: 8889
  servlet:
    context-path: /

logging:
  level:
    com.baomidou.mybatisplus.samples.quickstart: debug
    com.mytest.dao.mapper: debug




spring:
  datasource:
    driver-class-name: org.postgresql.Driver
    url: jdbc:postgresql://127.0.0.1:5432/mydb
    username: postgres
    password: 13qeadzc

  kafka:
    bootstrap-servers: 127.0.0.1:9092  #bootstrap-servers：连接kafka的地址，多个地址用逗号分隔
#    consumer:
#      group-id: myGroup
#      #true 自动提交 false：手动提交 对应ackmode
#      enable-auto-commit: false
#      auto-commit-interval: 100ms
#      properties:
#        session.timeout.ms: 15000
#      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
#      # smallest和largest才有效，如果smallest重新0开始读取，如果是largest从logfile的offset读取。一般情况下我们都是设置smallest
#      auto-offset-reset: earliest
#    producer:
#      retries: 0 #若设置大于0的值，客户端会将发送失败的记录重新发送
#      batch-size: 16384 #当将多个记录被发送到同一个分区时， Producer 将尝试将记录组合到更少的请求中。这有助于提升客户端和服务器端的性能。这个配置控制一个批次的默认大小（以字节为单位）。16384是缺省的配置
#      buffer-memory: 33554432 #Producer 用来缓冲等待被发送到服务器的记录的总字节数，33554432是缺省配置
#      key-serializer: org.apache.kafka.common.serialization.StringSerializer #关键字的序列化类
#      value-serializer: org.apache.kafka.common.serialization.StringSerializer #值的序列化类
#      #procedure要求leader在考虑完成请求之前收到的确认数，用于控制发送记录在服务端的持久化，其值可以为如下：
#      #acks = 0 如果设置为零，则生产者将不会等待来自服务器的任何确认，该记录将立即添加到套接字缓冲区并视为已发送。在这种情况下，无法保证服务器已收到记录，并且重试配置将不会生效（因为客户端通常不会知道任何故障），为每条记录返回的偏移量始终设置为-1。
#      #acks = 1 这意味着leader会将记录写入其本地日志，但无需等待所有副本服务器的完全确认即可做出回应，在这种情况下，如果leader在确认记录后立即失败，但在将数据复制到所有的副本服务器之前，则记录将会丢失。
#      #acks = all 这意味着leader将等待完整的同步副本集以确认记录，这保证了只要至少一个同步副本服务器仍然存活，记录就不会丢失，这是最强有力的保证，这相当于acks = -1的设置。
#      #可以设置的值为：all, -1, 0, 1
#      acks: 1
#      #设置幂等性
#      enable:
#        idempotence: true




mybatis-plus:
  global-config:
    db-config:
      db-type: MYSQL
      capital-mode: false #开启大写命名
      column-like: true #开启 LIKE 查询
mybatis:
  mapper-locations: classpath:mappers/*.xml
  type-aliases-package: com.example.demo.pojo
#spring.data.elasticsearch.cluster-nodes=xxxx:9300,xxx:9301
#spring.data.elasticsearch.cluster-name=b_cluster

#ES配置文件
#是否是单机
elasticsearch:
  isSingleton: true
  #ca位置
  capath: classpath:ca
#这个参数暂时保留
#  keystorepass=
#账号密码
  username:
  password:
# 三个es节点信息
  node1Ip: 127.0.0.1
  node1Port: 9200
  node1Scheme: http
#elasticsearch.node2Ip=22.94.239.72
#elasticsearch.node2Port=9200
#elasticsearch.node2Scheme=http
#elasticsearch.node3Ip=33.94.239.72
#elasticsearch.node3Port=9200
#elasticsearch.node3Scheme=http


